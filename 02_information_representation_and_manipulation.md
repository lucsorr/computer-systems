# 02: Representing and Manipulating Information

Modern computers store and process information represented as two-valued signals. These lowly binary digits, or bits, form the basis of the digital revolution.

Binary values work better when building machines that store and process information. Two-valued signals can readily be represented, stored, and transmitted. The electronic circuitry for storing and performing computations on two-valued signals is very simple and reliable, enabling manufacturers to integrate millions, or even billions, of such circuits on a single silicon chip.

When we group bits together and apply some interpretation that gives meaning to the different possible bit patterns, however, we can represent the elements of any finite set (numbers, letters and symbols, operations...)

We consider the three most important representations of numbers:

- Unsigned encodings are based on traditional binary notation, representing numbers greater than or equal to 0. 
- Two’s-complement encodings are the most common way to represent signed integers, that is, numbers that may be either positive or negative. 
- Floating-point encodings are a base-2 version of scientific notation for representing real numbers. Computers implement arithmetic operations, such as addition and multiplication, with these different representations, similar to the corresponding operations on integers and real numbers.

Computer representations use a limited number of bits to encode a number, and hence some operations can **overflow** when the results are too large to be represented. For example, in a 32 bit machine,

```t
200 * 300 * 400 * 500
```

yields 

```t
-884,901,888
```

**Integer** computer arithmetic satisfies many of the familiar properties of true integer arithmetic, like associative and conmutative properties; all these expressions yield the same result `-884,901,888`:

```t
(500 * 400) * (300 * 200)
((500 * 400) * 300) * 200
((200 * 500) * 300) * 400
400 * (200 * (300 * 500))
```

**Floating-point** arithmetic has altogether different mathematical properties. The product of a set of positive numbers will always be positive, although overflow will yield the special value +8. Floating-point arithmetic is not associative due to the finite precision of the representation.

The different mathematical properties of integer versus floating-point arithmetic stem from the difference in how they handle the finiteness of their representations—integer representations can encode a comparatively small range of values, but do so precisely, while floating-point representations can encode a wide range of values, but only approximately.

By studying the actual number representations, we can understand the ranges of values that can be represented and the properties of the different arithmetic operations. This understanding is critical to writing programs that work correctly over the full range of numeric values and that are portable across different combinations of machine, operating system, and compiler.

A number of computer security vulnerabilities have arisen due to some of the subtleties of computer arithmetic.

We will derive several ways to perform arithmetic operations by directly manipulating the bit-level representations of numbers Understanding these techniques will be important for understanding the machine-level code generated by compilers in their attempt to optimize the performance of arithmetic expression evaluation.

The C++ programming language is built upon C, using the exact same numeric representations and operations. Everything said in this chapter about C also holds for C++.

## 2.1 Information Storage

Rather than accessing individual bits in memory, most computers use blocks of 8 bits, or **bytes**, as the smallest addressable unit of memory. A machine-level program views memory as a very large array of bytes, referred to as **virtual memory**. Every byte of memory is identified by a unique number, known as its **address**, and the set of all possible addresses is known as the **virtual address space**.

This virtual address space is just a conceptual image presented to the machine-level program. The actual implementation uses a combination of dynamic random access memory (DRAM), flash memory, disk storage, special hardware, and operating system software to provide the program with what appears to be a monolithic byte array.

The compiler and run-time system partitions this memory space into more manageable units to store the different program objects, that is, program data, instructions, and control information. Various mechanisms are used to allocate and manage the storage for different parts of the program. This management is all performed within the virtual address space.

>For example, the value of a pointer in C—whether it points to an integer, a structure, or some other program object—is the virtual address of the first byte of some block of storage.
>
>The C compiler also associates type information with each pointer, so that it can generate different machine-level code to access the value stored at the location designated by the pointer depending on the type of that value. Although the C compiler maintains this type information, the actual machine-level program it generates has no information about data types. It simply treats each program object as a block of bytes and the program itself as a sequence of bytes.

>Pointers are a central feature of C. They provide the mechanism for referencing elements of data structures, including arrays. Just like a variable, a pointer has two aspects: its value and its type. The value indicates the location of some object, while its type indicates what kind of object (e.g., integer or floating-point number) is stored at that location.
> 
>Truly understanding pointers requires examining their representation and implementation at the machine level.

### 2.1.1 Hexadecimal Notation

A single byte consists of 8 bits. In binary notation, its value ranges from 00000000 to 11111111. When viewed as a decimal integer, its value ranges from 0 to 255.

Neither notation is very convenient for describing bit patterns; we write bit patterns as base-16, or hexadecimal numbers.

![Hexadecimal Notation](/assets/6.png)

### 2.1.2 Data Sizes

Every computer has a **word** size, indicating the nominal size of pointer data. Since a virtual address is encoded by such a word, the most important system parameter determined by the word size is the maximum size of the virtual address space. The word size determines the maximum memory address number it can represent; that is, for a machine with a w-bit word size, the virtual addresses can range from 0 to 2<sup>w</sup> - 1, giving the program access to at most 2<sup>w</sup> bytes.

In recent years, there has been a widespread shift from machines with 32- bit word sizes to those with word sizes of 64 bits. A 32-bit word size limits the virtual address space to 4 gigabytes (written 4 GB), that is, just over 4 × 10<sup>9</sup> bytes. Scaling up to a 64-bit word size leads to a virtual address space of 16 exabytes, or around 1.84 × 10<sup>19</sup> bytes.

Most 64-bit machines can also run programs compiled for use on 32-bit machines, a form of backward compatibility.

Computers and compilers support multiple data formats using different ways to encode data, such as integers and floating point, as well as different lengths.

The C language supports multiple data formats for both integer and floating- point data. Figure 2.3 shows the number of bytes typically allocated for different C data types.


![Type sizes](/assets/7.png)

Programmers should strive to make their programs portable across different machines and compilers. One aspect of portability is to make the program insensitive to the exact sizes of the different data types. The C standards set lower bounds on the numeric ranges of the different data types, as will be covered later, but there are no upper bounds (except with the fixed-size types).

### 2.1.3 Addressing and Byte Ordering

For program objects that span multiple bytes, we must establish two conventions: what the address of the object will be, and how we will order the bytes in memory. In virtually all machines, a multi-byte object is stored as a contiguous sequence of bytes, with the address of the object given by the smallest (the "first") address of the bytes used.

For ordering the bytes representing an object, there are two common conventions:

- Some machines choose to store the object in memory ordered from the least significant byte to most, while other machines store them from most to least. The former convention—where the least significant byte comes first—is referred to as **little endian**. 
- The latter convention—where the most significant byte comes first—is referred to as **big endian**.

Most Intel-compatible machines operate exclusively in little-endian mode. On the other hand, most machines from IBM and Oracle (arising from their acquisition of Sun Microsystems in 2010) operate in big-endian mode. Many recent microprocessor chips are **bi-endian**, meaning that they can be configured to operate as either little- or big-endian machines. In practice, however, byte ordering becomes fixed once a particular operating system is chosen.

There is no technological reason to choose one byte ordering convention over the other, and hence the arguments degenerate into bickering about sociopolitical issues. As long as one of the conventions is selected and adhered to consistently, the choice is arbitrary. For most application programmers, the byte orderings used by their machines are totally invisible; programs compiled for either class of machine give identical results. At times, however, byte ordering becomes an issue:

- When binary data are communicated over a network between different machines. A common problem is for data produced by a little-endian machine to be sent to a big-endian machine, or vice versa, leading to the bytes within the words being in reverse order for the receiving program. To avoid such problems, code written for networking applications must follow established conventions
- A second case where byte ordering becomes important is when looking at the byte sequences representing integer data. This occurs often when inspecting machine-level programs.
- When programs are written that circumvent the normal type system. In the C language, this can be done using a cast or a union to allow an object to be referenced according to a different data type from which it was created.

### 2.1.4 Representing Strings

A string in C is encoded by an array of characters terminated by the **null** (having value 0) character. Each character is represented by some standard encoding, with the most common being the ASCII character code.

>The Unicode Consortium has devised the most comprehensive and widely accepted standard for encoding text. The current Unicode standard (version 7.0) has a repertoire of over 100,000 characters supporting a wide range of languages, including the ancient languages of Egypt and Babylon.
>
>The base encoding, known as the “Universal Character Set” of Unicode, uses a 32-bit representation of characters. This would seem to require every string of text to consist of 4 bytes per character. However, alternative codings are possible where common characters require just 1 or 2 bytes, while less common ones require more. In particular, the UTF-8 representation encodes each character as a sequence of bytes, such that the standard ASCII characters use the same single-byte encodings as they have in ASCII, implying that all ASCII byte sequences have the same meaning in UTF-8 as they do in ASCII.

Text data are more platform independent than binary data.

### 2.1.5 Representing Code

Instruction codings are different. Different machine types use different and incompatible instructions and encodings. Even identical processors running different operating systems have differences in their coding conventions and hence are not binary compatible. Binary code is seldom portable across different combinations of machine and operating system.

As an example, consider a C function and the generated machine code when compiled on different machines:

```c
int sum(int x, int y) {
  return x + y;
}
```

**Linux 32** `55 89 e5 8b 45 0c 03 45 08 c9 c3 `
**Windows** `55 89 e5 8b 45 0c 03 45 08 5d c3 `
**Sun** `81 c3 e0 08 90 02 00 09` 
**Linux** `64 55 48 89 e5 89 7d fc 89 75 f8 03 45 fc c9 c3`

### 2.1.6 Introduction to Boolean Algebra

This started with the work of George Boole (1815– 1864) around 1850 and thus is known as Boolean algebra. Boole observed that by encoding logic values true and false as binary values 1 and 0, he could formulate an algebra that captures the basic principles of logical reasoning.

The simplest Boolean algebra is defined over the two-element set {0, 1}.

![Boolean operations](./assets/8.png)

Claude Shannon (1916–2001), who later founded the field of information theory, first made the connection between Boolean algebra and digital logic. In his 1937 master’s thesis, he showed that Boolean algebra could be applied to the design and analysis of networks of electromechanical relays. Although computer technology has advanced considerably since, Boolean algebra still plays a central role in the design and analysis of digital systems.

We can extend the four Boolean operations to also operate on bit vectors, strings of zeros and ones of some fixed length w. We define the operations over bit vectors according to their applications to the matching elements of the arguments.

Let a and b denote the bit vectors [a<sub>w-1</sub>, a<sub>w-2</sub>, . . . , a<sub>0</sub>] and [b<sub>w-1</sub>, b<sub>w-2</sub>, . . . , b<sub>0</sub>], respectively. We define _a & b_ to also be a bit vector of length _w_, where the _ith_ element equals a<sub>i</sub> & b<sub>i</sub>, for 0 = i < w.

As examples, consider the case where w = 4, and with arguments a = [0110] and b = [1100]. Then the four operations _a & b_, _a | b_, _a ^ b_, and _~b_ yield:

![Bit Operations](./assets/9.png)

One useful application of bit vectors is to represent finite sets. We can encode any subset A ? {0, 1, . . . , w - 1} with a bit vector [aw-1, . . . , a1, a0], where ai = 1if and only if i ? A. For example, recalling that we write aw-1 on the left and a0 on the right, bit vector a = [01101001] encodes the set A = {0, 3, 5, 6}, while bit vector b = [01010101]encodes the set B = {0, 2, 4, 6}. With this way of encoding sets, Boolean operations | and & correspond to set union and intersection, respectively, and ~ corresponds to set complement. Continuing our earlier example, the operation a & b yields bit vector [01000001], while A n B = {0, 6}.

#### Interesting! 

Computers generate color pictures on a video screen or liquid crystal display by mixing three different colors of light: red, green, and blue. Imagine a simple scheme, with three different lights, each of which can be turned on or off, projecting onto a glass screen:

![Colors](./assets/10.png)

We can then create eight different colors based on the absence (0) or presence (1) of light sources R, G, and B:

| R G B | Color  |
| --- | --- |
| 0 0 0 | Black  |
| 0 0 1 | Blue  |
| 0 1 0 | Green  |
| 0 1 1 | Cyan  |
| 1 0 0 | Red  |
| 1 0 1 | Magenta  |
| 1 1 0 | Yellow  |
| 1 1 1 | White |

Each of these colors can be represented as a bit vector of length 3, and we can apply Boolean operations to them.

### 2.1.7 Bit-Level Operations in C

One useful feature of C is that it supports bitwise Boolean operations. In fact, the symbols we have used for the Boolean operations are exactly those used by C: `|` for _or_, `&` for _and_, `~` for _not_, and `^` for _exclusive-or_. These can be applied to any “integral” data type,

Here are some examples of expression evaluation for data type char:

![Bit operations 2](./assets/11.png)

One common use of bit-level operations is to implement masking operations, where a mask is a bit pattern that indicates a selected set of bits within a word. As an example, the mask 0xFF (having ones for the least significant 8 bits) indicates the low-order byte of a word. The bit-level operation x & 0xFF yields a value consisting of the least significant byte of x, but with all other bytes set to 0. For example, with x = 0x89ABCDEF, the expression would yield 0x000000EF.

### 2.1.8 Logical Operations in C

C also provides a set of logical operators `||`, `&&`, and `!`, which correspond to the _or_, _and_, and _not_ operations of logic. These can easily be confused with the bit-level operations, but their behavior is quite different. The logical operations treat any nonzero argument as representing true and argument 0 as representing false. They return either 1 or 0, indicating a result of either true or false, respectively.

A second important distinction between the logical operators ‘&&’ and ‘||’ versus their bit-level counterparts ‘&’ and ‘|’ is that the logical operators do not evaluate their second argument if the result of the expression can be determined by evaluating the first argument. Thus, for example, the expression `a && 5/a` will never cause a division by zero, and the expression `p && *p++` will never cause the dereferencing of a null pointer. This is called **short-circuiting**

### 2.1.9 Shift Operations in C

C also provides a set of shift operations for shifting bit patterns to the left and to the right. For an operand x having bit representation [x<sub>w-1</sub>, x<sub>w-2</sub>, . . . , x<sub>0</sub>], the C expression `x << k` yields a value with bit representation [x<sub>w-k-1</sub>, x<sub>w-k-2</sub>, . . . , x<sub>0</sub>, 0, . . . , 0]. That is, x is shifted k bits to the left, dropping off the k most significant bits and filling the right end with k zeros. The shift amount should be a value between 0 and w - 1. Shift operations associate from left to right, so `x << j << k` is equivalent to `(x << j) << k`.

There is a corresponding right shift operation, written in C as x >> k, but it has a slightly subtle behavior. Generally, machines support two forms of right shift:

- Logical. A logical right shift fills the left end with k zeros, giving a result [0, . . . , 0, x<sub>w-1</sub>, x<sub>w-2</sub>, . . . x<sub>k</sub>]. 
- Arithmetic. An arithmetic right shift fills the left end with k repetitions of the most significant bit, giving a result [x<sub>w-1</sub>, . . . , x<sub>w-1</sub>, x<sub>w-1</sub>, x<sub>w-2</sub>, . . . x<sub>k</sub>]. This convention might seem peculiar, but as we will see, it is useful for operating on signed integer data.

As examples, the following table shows the effect of applying the different shift operations to two different values of an 8-bit argument x:

![Right shifts](./assets/12.png)

The C standards do not precisely de?ne which type of right shift should be used with signed numbers—either arithmetic or logical shifts may be used. This unfortunately means that any code assuming one form or the other will potentially encounter portability problems. In practice, however, almost all compiler/machine combinations use arithmetic right shifts for signed data, and many programmers assume this to be the case.

## 2.2 Integer Representations

We will describe two different ways bits can be used to encode integers:

- one that can only represent nonnegative numbers, 
- and one that can represent negative, zero, and positive numbers. 

We will see later that they are strongly related both in their mathematical properties and their machine-level implementations. We also investigate the effect of expanding or shrinking an encoded integer to fit a representation with a different length.

### Terminology Reference

This is the mathematical terminology we use to define and characterize how computers encode and operate on integer data:

| Symbol | Type |  Meaning |
| --- | --- | --- |
| B2U<sub>w</sub>| Function | Binary to unsigned |
| B2T<sub>w</sub>| Function | Binary to two’s complement  |
| U2B<sub>w</sub>| Function | Unsigned to binary |
| U2T<sub>w</sub>| Function | Unsigned to two’s complement |
| T2B<sub>w</sub>| Function | Two’s complement to binary |
| T2U<sub>w</sub>| Function | Two’s complement to unsigned |
| TMin<sub>w</sub>| Constant | Minimum two’s-complement value |
| TMax<sub>w</sub>| Constant | Maximum two’s-complement value |
| UMax<sub>w</sub>| Constant | Maximum unsigned value|
| +wt | Operation | Two’s-complement addition |
| +wu | Operation | Unsigned addition 121 |
| *wt | Operation | Two’s-complement multiplication |
| *wu | Operation | Unsigned multiplication |
| -wt | Operation | Two’s-complement negation |
| -wu | Operation | Unsigned negation|

### 2.2.1 Integral Data Types

C supports a variety of integral data types—ones that represent ﬁnite ranges of integers. Each type can specify a size with keyword `char`, `short`, `long`, as well as an indication of whether the represented numbers are all nonnegative (declared as `unsigned`), or possibly negative (the default.)

![Types](./assets/14.png)
![Types2](./assets/13.png)

One important feature to note is that the ranges are not symmetric—the range of negative numbers extends one further than the range of positive numbers.

### 2.2.2 Unsigned Encodings

#### Principle: **Definition of unsigned encoding**

Let us consider an integer data type of _w_ bits. We write a bit vector as either x<sup>➡</sup>, to denote the entire vector, or as [x<sub>w-1</sub>, x<sub>w-2</sub>, . . . , x<sub>0</sub>] to denote the individual bits within the vector.

![Types](./assets/15.png)
![](assets/2023-12-19-13-38-13.png)

The function B2U<sub>w</sub> maps strings of zeros and ones of length _w_ to nonnegative integers.

#### Principle: **Uniqueness of unsigned encoding**

The unsigned binary representation has the important property that every number between 0 and 2 _w_ − 1 has a unique encoding as a  _w_-bit value.

Function B2U<sub>w</sub> is a bijection. The mathematical term bijection refers to a function f that goes two ways; in this case, the function B2U<sub>w</sub> maps each bit vector of length w to a unique number between 0 and 2 _w_ − 1, and it has an inverse, which we call U2B<sub>w</sub> (for “unsigned to binary”), that maps each number in the range 0 to 2 _w_ − 1 to a unique pattern of _w_ bits.

### 2.2.3 Two's Complement 

The most common computer representation of signed numbers is known as two’s-complement form. This is defined by interpreting the most significant bit of the word to have negative weight. We express this interpretation as a function B2T<sub>w</sub> (for “binary to two’s complement” length w):

#### Principle: **Definition of two's-complement encoding**

![](assets/2023-12-19-13-47-37.png)

The most significant bit xw-1 is also called the sign bit. Its “weight” is -2<sup>w-1</sup>, the negation of its weight in an unsigned representation. When the sign bit is set to 1, the represented value is negative, and when set to 0, the value is nonnegative.

![](assets/2023-12-19-13-49-34.png)

The least representable value is given by bit vector [1,0 . . . 0] (set the bit with negative weight but clear all others), having integer value TMin<sub>w</sub> = -2<sup>w-1</sup>. The greatest value is given by bit vector [0,1 . . . 1] (clear the bit with negative weight but set all others), having integer value 2<sup>w-1</sup> -1.

Every number within the representable range has a unique encoding as a _w_-bit two’s-complement number:

#### Principle: **Uniqueness of two's complement encoding**

Function B2Tw is a bijection. 

We define function T2B<sub>w</sub> (for two's complement to binary) to be the inverse of B2T<sub>w</sub>. That is, for a number x, such that TMin<sub>w</sub> . x . TMax<sub>w</sub>, T2B<sub>w</sub>(x) is the (unique) _w_-bit pattern that encodes x.

Some points to highlight:

The two’s-complement range is asymmetric: |_TMin_| = |_TMax_| + 1; that is, there is no positive counterpart to _TMin_. This leads to some peculiar properties of two’s-complement arithmetic and can be the source of subtle program bugs. The reason is that 0 is included in the nonnegative (so we have one less positive)

Second, the maximum unsigned value is just over twice the maximum two’s-complement value: _UMax_ = _2TMax_ + 1. All of the bit patterns that denote negative numbers in two’s-complement notation become positive values in an unsigned representation.

>For some programs, it is essential that data types be encoded using representations with specific sizes. For example, when writing programs to enable a machine to communicate over the Internet according to a standard protocol, it is important to have data types compatible with those specified by the protocol.

The C standards do not require signed integers to be represented in two’s complement form, but nearly all machines do so. Programmers who are concerned with maximizing portability across all possible machines should not assume any particular range of representable values, nor should they assume any particular representation of signed numbers. On the other hand, many programs are written assuming a two’s-complement representation of signed numbers, and the “typical” ranges shown in Figures 2.9 and 2.10, and these programs are portable across a broad range of machines and compilers.

### 2.2.4 Conversions between Signed and Unsigned

C allows casting between different numeric data types. For example, suppose variable x is declared as int and u as unsigned. The expression (unsigned) x converts the value of x to an unsigned value, and (int) u converts the value of u to a signed integer.

The effect of casting is to keep the bit values identical but change how these bits are interpreted. The underlying bit representation stays the same. This is a general rule for how most C implementations handle conversions between signed and unsigned numbers with the same word size—the numeric values might change, but the bit patterns do not.

#### Principle: **Conversions from two's complement to unsigned**

![](assets/2023-12-19-14-12-36.png)

![](assets/2023-12-19-14-13-22.png)

As it shows, when mapping a signed number to its unsigned counterpart, negative numbers are converted to large positive numbers, while nonnegative numbers remain unchanged.

#### Principle: **Conversion from unsigned to two's complement**

![](assets/2023-12-21-16-29-46.png)

![](assets/2023-12-21-16-30-01.png)

To summarize, we considered the effects of converting in both directions between unsigned and two's-complement representations. For values x in the range 0 ≤ x ≤ TMax<sub>w</sub>, we have T2U<sub>w</sub>(x) = x and U2T<sub>w</sub>(x) = x. That is, numbers in this range have identical unsigned and two's-complement representations. For values outside of this range, the conversions either add or subtract 2<sup>w</sup>.

### 2.2.5 Signed versus Unsigned in C

C supports both signed and unsigned arithmetic for all of its integer data types. Although the C standard does not specify a particular representation of signed numbers, almost all machines use two’s complement. Generally, most numbers are signed by default.

C allows conversion between unsigned and signed; most systems follow the rule that the underlying bit representation does not change.

This rule has the effect of applying the function U2T<sub>w</sub> when converting from unsigned to signed, and T2U<sub>w</sub> when converting from signed to unsigned, where w is the number of bits for the data type.

Conversions can happen due to explicit casting:

```c
int tx, ty; 
unsigned ux, uy; 

tx = (int) ux; 
uy = (unsigned) ty;
```

Alternatively, they can happen implicitly when an expression of one type is assigned to a variable of another:

```c
int tx, ty;
unsigned ux, uy;

tx = ux; /* Cast to signed */
uy = ty; /* Cast to unsigned */
```

### 2.2.6 Expanding the Bit Representation of a Number

One common operation is to convert between integers having different word sizes while retaining the same numeric value. Of course, this may not be possible when
the destination data type is too small to represent the desired value. Converting from a smaller to a larger data type, however, should always be possible.

To convert an unsigned number to a larger data type, we can simply add leading zeros to the representation; this operation is known as zero extension:

![](assets/2023-12-21-16-46-47.png)

#### Principle: Expansion of an unsigned number by _zero_ extension

![](assets/2023-12-21-16-46-16.png)

#### Principle: Expansion of a two's-complement number by _sign_ extension

For converting a two’s-complement number to a larger data type, the rule is to perform a sign extension, adding copies of the most significant bit to the representation, expressed by the following principle:

![](assets/2023-12-21-16-46-04.png)

Sign extension preserves the value of a two’s-complement number.

### 2.2.7 Truncating Numbers

If we reduce the number of bits that represent a number, rather than extending a value with extra bits, we are **truncating** the number.

This can happen when, for instance, we cast `x` to be `short`, truncating a 32-bit `int` to a 16-bit `short`:

```c
int x = 53191;
short sx = (short) x; /* -12345 */
int y = sx; /* -12345 */
```

When truncating a _w_-bit number _x→_ = [x<sub>w-1</sub>, x<sub>w-2</sub>, . . . , x<sub>0</sub>] to a _k_-bit number, we drop the high-order _w - k_ bits, giving a bit vector _x→'_ = [x<sub>k-1</sub>, x<sub>k-2</sub>, . . . , x<sub>0</sub>].

Truncating a number can alter its value—a form of overflow. For an unsigned number, we can readily characterize the numeric value that will result.

#### Principle: **Truncation of an unsigned number**

![](assets/2023-12-22-16-47-15.png)

The intuition behind this principle is simply that all of the bits that were truncated have weights of the form 2i , where i ≥ k, and therefore each of these weights reduces to zero under the modulus operation.

#### Principle: **Truncation of a two's-complement number**

![](assets/2023-12-22-16-48-43.png)

In this formulation, x mod 2<sup>k</sup> will be a number between 0 and 2<sup>k - 1</sup>. Applying function U2T<sub>k</sub> to it will have the effect of converting the most significant bit x<sup>k - 1</sup> from having weight 2<sup>k - 1</sup> to having weight −2<sup>k - 1</sup>.

### 2.2.8 Advice on Signed versus Unsigned

As we have seen, the implicit casting of signed to unsigned leads to some nonintuitive behavior. Nonintuitive features often lead to program bugs, and ones involving the nuances of implicit casting can be especially difficult to see. Since the casting takes place without any clear indication in the code, programmers often overlook its effects.

One way to avoid such bugs is to never use unsigned numbers. In fact, few languages other than C support unsigned integers.

Unsigned values are very useful when we want to think of words as just collections of bits with no numeric interpretation. This occurs, for example, when packing a word with flags describing various Boolean conditions. Addresses are naturally unsigned, so systems programmers find unsigned types to be helpful. Unsigned values are also useful when implementing mathematical packages for
modular arithmetic and for multiprecision arithmetic, in which numbers are represented by arrays of words.

## 2.3 Integer Arithmetic

It's important to consider the **artifacts of the finite computer arithmetic**. Understanding the nuances of computer arithmetic can help programmers write more reliable code. For example, adding two positive numbers can yield a negative result, and that the comparison `x < y` can yield a different result than the comparison `x-y < 0`.

### 2.3.1 Unsigned Addition

#### Principle: **Unsigned addition**

![](assets/2023-12-23-15-57-32.png)

The normal case preserves the value of x + y, while the overflow case has the effect of decrementing this sum by 2<sub>w</sub>.

An arithmetic operation is said to overflow when the full integer result cannot fit within the word size limits of the data type.

![](assets/2023-12-23-15-59-04.png)

#### Principle: **Detecting overflow of unsigned addition**

![](assets/2023-12-23-15-59-54.png)

>Modular addition forms a mathematical structure known as an **abelian** group, named after the Norwegian mathematician Niels Henrik Abel (1802–1829). That is, it is commutative (that’s where the “abelian” part comes in) and associative; it has an identity element 0, and every element has an additive inverse.

#### Principle: **Unsigned negation**

![](assets/2023-12-23-16-02-50.png)

### 2.3.2 Two's-Complement Addition

With two’s-complement addition, we must decide what to do when the result is either too large (positive) or too small (negative) to represent.

We avoid ever-expanding data sizes by truncating the representation to _w_ bits.

#### Principle: **Two's complement addition**

![](assets/2023-12-23-16-05-29.png)

When the sum x + y exceeds TMax<sub>w</sub> (case 4), we say that positive overflow has occurred. In this case, the effect of truncation is to subtract 2<sub>w</sub> from the sum. When the sum x + y is less than TMin<sub>w</sub> (case 1), we say that negative overflow has occurred. In this case, the effect of truncation is to add 2<sub>w</sub> to the sum. The w-bit two’s-complement sum of two numbers has the exact same bit-level representation as the unsigned sum. In fact, most computers use the same machine instruction to perform either unsigned or signed addition:

![](assets/2023-12-23-16-08-20.png)

![](assets/2023-12-23-16-08-41.png)

#### Principle: **Detecting overflow in two's-complement addition**

![](assets/2023-12-23-16-09-52.png)

### 2.3.3 Two's-Complement Negation

We can see that every number x in the range TMin<sub>w</sub> ≤ x ≤ TMax<sub>w</sub> has an additive inverse under +tw, which we denote -tw x as follows:

#### Principle: **Two's complement negation**

![](assets/2023-12-24-15-41-52.png)

That is, for w-bit two’s-complement addition, TMin<sub>w</sub> is its own additive inverse, while any other value x has −x as its additive inverse.

### 2.3.4 Unsigned Multiplication

#### Principle: **Unsigned multiplicaiton**

![](assets/2023-12-24-15-51-15.png)

Integers x and y in the range 0 ≤ x, y ≤ 2<sup>w</sup> − 1 can be represented as w-bit unsigned numbers, but their product x . y can range between 0 and (2<sup>w</sup> − 1)<sup>2</sup> = 2<sup>2w</sup> − 2<sup>w + 1</sup> + 1. This could require as many as 2w bits to represent. Instead, unsigned multiplication in C is defined to yield the w-bit value given by the low-order w bits of the 2w-bit integer product.

Truncating an unsigned number to w bits is equivalent to computing its value modulo 2<sup>w</sup>:

### 2.3.5 Two's Complement Multiplication

#### Principle: **Two's complement multiplication**

Signed multiplication in C generally is performed by truncating the 2w-bit product to w bits.

We denote this value as x *tw y. Truncating a two’s-complement number to w bits is equivalent to first computing its value modulo 2<sup>2</sup> and then converting from unsigned to two’s complement:

![](assets/2023-12-24-15-53-59.png)

#### Principle: **Bit-level equivalence of unsigned and two's complement multiplication**

The bit-level representation of the product operation is identical for both unsigned and two’s-complement multiplication

![](assets/2023-12-24-15-58-14.png)

![](assets/2023-12-24-15-58-54.png)

### 2.3.6 Multiplying by Constants

Historically, the integer multiply instruction on many machines was fairly slow, requiring 10 or more clock cycles, whereas other integer operations—such as addition, subtraction, bit-level operations, and shifting—required only 1 clock cycle. As a consequence, one important optimization used by compilers is to attempt to replace multiplications by constant factors with combinations of shift and addition operations. 

We will first consider the case of multiplying by a power of 2, and then we will generalize this to arbitrary constants.

#### Principle: **Multiplication by a power of 2**

![](assets/2023-12-25-17-42-28.png)

So, for example, 11 can be represented for w = 4 as [1011]. Shifting this left by k = 2 yields the 6-bit vector [101100], which encodes the unsigned number 11 . 4 = 44.

#### Principle: **Unsigned multiplication by a power of 2**

![](assets/2023-12-25-17-43-33.png)

Note that multiplying by a power of 2 can cause overflow with either unsigned or two’s-complement arithmetic. Our result shows that even then we will get the same effect by shifting. Returning to our earlier example, we shifted the 4-bit pattern [1011] (numeric value 11) left by two positions to get [101100] (numeric value 44). Truncating this to 4 bits gives [1100] (numeric value 12 = 44 mod 16).

Given that integer multiplication is more costly than shifting and adding, many C compilers try to remove many cases where an integer is being multiplied by a constant with combinations of shifting, adding, and subtracting.

Of course, the trade-off between using combinations of shifting, adding, and subtracting versus a single multiplication instruction depends on the relative speeds of these instructions, and these can be highly machine dependent. Most compilers only perform this optimization when a small number of shifts, adds, and subtractions suffice.

### 2.3.7 Dividing by Powers of 2

Integer division on most machines is even slower than integer multiplication— requiring 30 or more clock cycles. Dividing by a power of 2 can also be performed using shift operations, but we use a right shift rather than a left shift. The two different right shifts—logical and arithmetic—serve this purpose for unsigned and two’s-complement numbers, respectively.

![](assets/2023-12-25-17-50-11.png)

![](assets/2023-12-25-17-53-53.png)

#### Principle: **Unsigned division by a power of 2**

![](assets/2023-12-25-17-53-05.png)

![](assets/2023-12-25-17-54-40.png)

The case for dividing by a power of 2 with two’s-complement arithmetic is slightly more complex. First, the shifting should be performed using an arithmetic right shift, to ensure that negative values remain negative.

#### Principle: **Two’s-complement division by a power of 2, rounding down**

![](assets/2023-12-25-17-57-03.png)

We can correct for the improper rounding that occurs when a negative number is shifted right by “biasing” the value before shifting.

#### Principle: **Two’s-complement division by a power of 2, rounding up** 

![](assets/2023-12-25-17-59-27.png)

![](assets/2023-12-25-17-59-41.png)

Figure 2.30 demonstrates how adding the appropriate bias before performing the arithmetic right shift causes the result to be correctly rounded.

We now see that division by a power of 2 can be implemented using logical or arithmetic right shifts. This is precisely the reason the two types of right shifts are available on most machines. Unfortunately, this approach does not generalize to
division by arbitrary constants. Unlike multiplication, we cannot express division by arbitrary constants K in terms of division by powers of 2.

### 2.3.8 Final Thought on Integer Arithmetic

The “integer” arithmetic performed by computers is really a form of modular arithmetic. The finite word size used to represent numbers limits the range of possible values, and the resulting operations can overflow.

The two’s-complement representation provides a clever way to represent both negative and positive values, while using the same bit-level implementations as are used to perform unsigned arithmetic—operations such as addition, subtraction, multiplication, and even division have either identical or very similar bit-level behaviors, whether the operands are in unsigned or two’s complement form.

Some of the conventions in the C language can yield some surprising results, and these can be sources of bugs that are hard to recognize or understand. We have especially seen that the `unsigned` data type, while conceptually straightforward, can lead to behaviors that even experienced programmers do not expect. We have also seen that this data type can arise in unexpected ways—for example, when writing integer constants and when invoking library routines.

## 2.4 Floating Point

A floating-point representation encodes rational numbers of the form V = x × 2y. It is useful for performing computations involving very large numbers (|V| >> 0), numbers very close to 0 (|V| << 1), and more generally as an approximation to real arithmetic.

Up until the 1980s, every computer manufacturer devised its own conventions for how floating-point numbers were represented and the details of the operations performed on them. In addition, they often did not worry too much about the accuracy of the operations, viewing speed and ease of implementation as being more critical than numerical precision.

All of this changed around 1985 with the advent of IEEE Standard 754, a carefully crafted standard for representing floating-point numbers and the operations performed on them. This effort started in 1976 under Intel’s sponsorship with the design of the 8087, a chip that provided floating-point support for the 8086 processor. Intel hired William Kahan, a professor at the University of California, Berkeley, as a consultant to help design a floating-point standard for its future processors. They allowed Kahan to join forces with a committee generating an industry-wide standard under the auspices of the Institute of Electrical and Electronics Engineers (IEEE). The committee ultimately adopted a standard close to the one Kahan had devised for Intel. Nowadays, virtually all computers support what has become known as IEEE floating point. This has greatly improved the portability of scientific application programs across different machines.

### 2.4.1 Fractional Binary Numbers